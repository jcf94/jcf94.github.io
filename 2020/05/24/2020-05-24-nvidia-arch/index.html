<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 4.2.0">

  <link rel="search" type="application/opensearchdescription+xml" href="https://jcf94.com/sitesearch.xml" title="Chenfan Blog">
  <link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">
  <link rel="manifest" href="/manifest.json">
  <meta name="msapplication-config" content="/browserconfig.xml">
  <meta http-equiv="Cache-Control" content="no-transform">
  <meta http-equiv="Cache-Control" content="no-siteapp">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css">
  <link rel="stylesheet" href="//cdn.jsdelivr.net/gh/fancyapps/fancybox@3/dist/jquery.fancybox.min.css">
  <link rel="stylesheet" href="/lib/pace/pace-theme-big-counter.min.css">
  <script src="/lib/pace/pace.min.js"></script>

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"jcf94.com","root":"/","scheme":"Gemini","version":"7.8.0","exturl":false,"sidebar":{"position":"right","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":true,"show_result":true,"style":"mac"},"back2top":{"enable":true,"sidebar":false,"scrollpercent":true},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":true,"mediumzoom":false,"lazyload":true,"pangu":true,"comments":{"style":"tabs","active":"gitalk","storage":true,"lazyload":true,"nav":null,"activeClass":"gitalk"},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.xml"};
  </script>

  <meta name="description" content="最近 NV 刚发布了新架构的 GPU，自之前理过 Intel CPU 的架构变化 后再来理一下 GPU 的。 硬&#x2F;软件接口那篇有介绍过 GPU 的结构，当时也是以 Fermi 架构为例的，NV 很有意思的是会用一些历史上杰出的科学家的名字来命名自己的硬件架构。 总体上，NV GPU 用到的 SIMT 基本编程模型都是一致的，每一代相对前代基本都会在 SM 数量、SM 内部各个处理单元的流水线结构等">
<meta property="og:type" content="article">
<meta property="og:title" content="NVIDIA GPU 架构演进">
<meta property="og:url" content="https://jcf94.com/2020/05/24/2020-05-24-nvidia-arch/index.html">
<meta property="og:site_name" content="Chenfan Blog">
<meta property="og:description" content="最近 NV 刚发布了新架构的 GPU，自之前理过 Intel CPU 的架构变化 后再来理一下 GPU 的。 硬&#x2F;软件接口那篇有介绍过 GPU 的结构，当时也是以 Fermi 架构为例的，NV 很有意思的是会用一些历史上杰出的科学家的名字来命名自己的硬件架构。 总体上，NV GPU 用到的 SIMT 基本编程模型都是一致的，每一代相对前代基本都会在 SM 数量、SM 内部各个处理单元的流水线结构等">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://jcf94.com/download/2018-02-06-cod2-Fermi.svg">
<meta property="og:image" content="https://jcf94.com/download/2020-05-24-nvidia-arch-kepler.png">
<meta property="og:image" content="https://jcf94.com/download/2020-05-24-nvidia-arch-maxwell.png">
<meta property="og:image" content="https://jcf94.com/download/2020-05-24-nvidia-arch-pascal.png">
<meta property="og:image" content="https://jcf94.com/download/2020-05-24-nvidia-arch-volta.png">
<meta property="og:image" content="https://jcf94.com/download/2020-05-24-nvidia-arch-tensorcore1.png">
<meta property="og:image" content="https://jcf94.com/download/2020-05-24-nvidia-arch-tensorcore2.png">
<meta property="og:image" content="https://jcf94.com/download/2020-05-24-nvidia-arch-simt-old.png">
<meta property="og:image" content="https://jcf94.com/download/2020-05-24-nvidia-arch-simt-design.png">
<meta property="og:image" content="https://jcf94.com/download/2020-05-24-nvidia-arch-simt-new.png">
<meta property="article:published_time" content="2020-05-24T08:11:19.000Z">
<meta property="article:modified_time" content="2020-09-05T10:51:29.256Z">
<meta property="article:author" content="Jcf94">
<meta property="article:tag" content="Microarchitecture">
<meta property="article:tag" content="NVIDIA">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://jcf94.com/download/2018-02-06-cod2-Fermi.svg">

<link rel="canonical" href="https://jcf94.com/2020/05/24/2020-05-24-nvidia-arch/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'en'
  };
</script>

  <title>NVIDIA GPU 架构演进 | Chenfan Blog</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

<link rel="alternate" href="/atom.xml" title="Chenfan Blog" type="application/atom+xml">
</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">Chenfan Blog</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
      <p class="site-subtitle" itemprop="description">Do cool things that matter.</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="menu">
        <li class="menu-item menu-item-paper-reading">

    <a href="/2017/08/18/2017-08-18-paper/" rel="section"><i class="fa fa-fw fa-bookmark"></i>Paper Reading</a>

  </li>
        <li class="menu-item menu-item-links">

    <a href="/links/" rel="section"><i class="fa fa-fw fa-link"></i>Links</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about/" rel="section"><i class="fa fa-fw fa-user"></i>About</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>Search
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off"
           placeholder="Searching..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result">
  <div id="no-result">
    <i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>
  </div>
</div>

    </div>
  </div>

</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>
  <div class="reading-progress-bar"></div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://jcf94.com/2020/05/24/2020-05-24-nvidia-arch/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/photo.jpg">
      <meta itemprop="name" content="Jcf94">
      <meta itemprop="description" content="To live is to change the world.">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Chenfan Blog">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          NVIDIA GPU 架构演进
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2020-05-24 16:11:19" itemprop="dateCreated datePublished" datetime="2020-05-24T16:11:19+08:00">2020-05-24</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2020-09-05 18:51:29" itemprop="dateModified" datetime="2020-09-05T18:51:29+08:00">2020-09-05</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Computer-Architecture/" itemprop="url" rel="index"><span itemprop="name">Computer Architecture</span></a>
                </span>
            </span>

          
            <span class="post-meta-item" title="Views" id="busuanzi_container_page_pv" style="display: none;">
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
              </span>
              <span class="post-meta-item-text">Views: </span>
              <span id="busuanzi_value_page_pv"></span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <p>最近 NV 刚发布了新架构的 GPU，自之前理过 <a href="/2018/02/13/2018-02-13-intel/">Intel CPU 的架构变化</a> 后再来理一下 GPU 的。</p>
<p><a href="/2018/02/12/2018-02-12-cod3/#6-6-Introduction-to-Graphics-Processing-Units">硬/软件接口</a>那篇有介绍过 GPU 的结构，当时也是以 Fermi 架构为例的，NV 很有意思的是会用一些历史上杰出的科学家的名字来命名自己的硬件架构。</p>
<p>总体上，NV GPU 用到的 SIMT 基本编程模型都是一致的，每一代相对前代基本都会在 SM 数量、SM 内部各个处理单元的流水线结构等等方面有一些升级和改动。这篇暂时不涉及到渲染管线相关的部分，其他诸如多少 nm 工艺、内存频率提升等等也都先略过，只关注计算相关的硬件架构演进。</p>
<a id="more"></a>

<hr>
<h1 id="Tesla"><a href="#Tesla" class="headerlink" title="Tesla"></a>Tesla</h1><p>关于初代 GPU 的架构，找到的资料不太多，基本上都是从 Fermi 开始的。</p>
<h1 id="Fermi"><a href="#Fermi" class="headerlink" title="Fermi"></a>Fermi</h1><p>Compute Capability: 2.0, 2.1</p>
<p><img data-src="https://jcf94.com/download/2018-02-06-cod2-Fermi.svg" alt="Fermi 架构 SM"></p>
<p>每个 SM 中包含：</p>
<ul>
<li>2 个 Warp Scheduler/Dispatch Unit</li>
<li>32 个 CUDA Core（分在两条 lane 上，每条分别是 16 个）<ul>
<li>每个 CUDA Core 里面是 1 个单精浮点单元（FPU）和 1 个整数单元（ALU），可以直接做 FMA 的乘累加</li>
<li>每个 cycle 可以跑 16 个双精的 FMA</li>
</ul>
</li>
<li>16 个 LD/ST Unit</li>
<li>4 个 SFU</li>
</ul>
<blockquote>
<p>我的理解是做一个双精 FMA 需要用到两个 CUDA Core？所以是 32 / 2 = 16</p>
</blockquote>
<h1 id="Kepler"><a href="#Kepler" class="headerlink" title="Kepler"></a>Kepler</h1><p>Compute Capability: 3.0, 3.2, 3.5, 3.7</p>
<p>这一代 SM 整体结构上跟之前是一致的，只不过升级完了以后又往里面塞进去了更多的运算单元，其他部分也没有做太大的改动。</p>
<p><img data-src="https://jcf94.com/download/2020-05-24-nvidia-arch-kepler.png" alt="Kepler 架构 SM"></p>
<p>每个 SM（这里叫 SMX 了）中包含：</p>
<ul>
<li>4 个 Warp Scheduler，8 个 Dispatch Unit</li>
<li>CUDA Core 增加到 192 个（4 * 3 * 16，每条 lane 上还是 16 个）</li>
<li>单独分出来 64 个（4 * 16，每条 lane 上 16 个）双精运算单元。</li>
<li>SFU 和 LD/ST Unit 分别也都增加到 32 个</li>
</ul>
<p>Kepler 是附近几代在硬件上直接有双精运算单元的架构，不用通过单精单元去做双精运算了，所以对比前后几代的双精浮点的性能话会发现 Kepler 要高出一截。</p>
<h1 id="Maxwell"><a href="#Maxwell" class="headerlink" title="Maxwell"></a>Maxwell</h1><p>Compute Capability: 5.0, 5.2, 5.3</p>
<p><img data-src="https://jcf94.com/download/2020-05-24-nvidia-arch-maxwell.png" alt="Maxwell 架构 SM"></p>
<p>可能是觉得 Kepler 往一个 SM 里面塞了太多东西，其实最终效率也并没有那么高，这一代的 SM 开始做减法了，每个 SM（SMM）中包含：</p>
<ul>
<li>4 个 Warp Scheduler，8 个 Dispatch Unit</li>
<li>128 个 CUDA Core（4 * 32）</li>
<li>32 个 SFU 和 LD/ST Unit（4 * 8）</li>
</ul>
<p>Kepler 里面 192 这个数字也被诟病了（不是 2 的倍数）。</p>
<p>这些硬件单元的流水线分布也不再是像 Kepler 那样大锅炖了，而是有点像是把 4 个差不多像是 Fermi 的 SM 拼在一起组成一个 SM：<br>每个 Process Block 里面是：</p>
<ul>
<li>1 个 Warp Scheduler 和 2 个 Dispatch Unit</li>
<li>32 个 CUDA Core</li>
<li>8 个 SFU 和 LD/ST Unit</li>
</ul>
<p>图上没有看到之前 lane 的标记，不过我猜应该也还是 4 条，两条 CUDA Core 的 lane，1 条 SFU，1 条 LD/ST Unit。</p>
<p>应该是工艺和频率的提升，Maxwell 每个 CUDA Core 的性能相比 Kepler 提升了 1.4 倍，每瓦性能提升了 2 倍。对 CUDA Core 的详细结构没有再介绍，姑且认为从 Fermi 开始一直到以后 CUDA Core 内部的结构都没有什么改变。</p>
<p>另外一点是，前面说到的双精单元在这一代上也移除了。</p>
<blockquote>
<p>也许是觉得认为只有少数 HPC 科学计算才用的上的双精单元在这代上不太有必要吧。</p>
</blockquote>
<h1 id="Pascal"><a href="#Pascal" class="headerlink" title="Pascal"></a>Pascal</h1><p>Compute Capability: 6.0, 6.1, 6.2</p>
<p>这一代可以说是有了质的飞跃，还是先从 SM 开始：</p>
<p><img data-src="https://jcf94.com/download/2020-05-24-nvidia-arch-pascal.png" alt="Pascal 架构 SM"></p>
<p>可以看到一个 SM 内的部分作了进一步的精简，整体思路是 SM 内部包含的东西越来越少，但是总体的片上 SM 数量每一代都在不断增加，每个 SM 中包含：</p>
<ul>
<li>2 个 Warp Scheduler，4 个 Dispatch Unit</li>
<li>64 个 CUDA Core（2 * 32）</li>
<li>32 个双精浮点单元（2 * 16，双精回来了！）</li>
<li>16 个 SFU 和 LD/ST Unit（2 * 8）</li>
</ul>
<p>一个 SM 里面包含的 Process Block 数量减少到了 2 个，每个 Process Block 内部的结构倒是 Maxwell 差不多：</p>
<ul>
<li>1 个 Warp Scheduler 和 2 个 Dispatch Unit</li>
<li>32 个 CUDA Core</li>
<li>多了 16 个 DP Unit</li>
<li>8 个 SFU 和 LD/ST Unit</li>
</ul>
<blockquote>
<p>单个 Process Block 的流水线增加到 6 条 lane 了？</p>
</blockquote>
<p>其他质变的升级包括：</p>
<ul>
<li>面向 Deep Learning 做了一些专门的定制（CuDNN 等等）</li>
<li>除了 PCIE 以外，P100 还有 NVLink 版，单机卡间通信带宽逆天了，多机之间也能通过 Infiniband 进一步扩展 NVLink（GPUDirect）<blockquote>
<p>然后 NV 现在已经把 Infiniband 行业的龙头 Mellanox 给收购了……说不定那时候就已经有这个想法了呢</p>
</blockquote>
</li>
<li>P100 上把 GDDR5 换成了 HBM2，Global Memory 的带宽涨了一个数量级</li>
<li>16nm FinFET 工艺，性能提升一大截，功耗还能控制住不怎么增加</li>
<li>Unified Memory，支持把 GPU 的显存和 CPU 的内存统一到一个相同的地址空间，驱动层自己会做好 DtoH 和 HtoD 的内存拷贝，编程模型上更加友好了</li>
</ul>
<p>CUDA Core 在这一代也终于有了升级，现在硬件上直接支持 FP16 的半精计算了，半精性能是单精的 2 倍，猜测应该是一个单精单元用来算两个半精的计算。</p>
<h1 id="Volta"><a href="#Volta" class="headerlink" title="Volta"></a>Volta</h1><p>Compute Capability: 7.0, 7.2</p>
<p>又一个针对深度学习的质变 Feature，Tensor Core！</p>
<p><img data-src="https://jcf94.com/download/2020-05-24-nvidia-arch-volta.png" alt="Volta 架构 SM"></p>
<p>看到 SM 的时候我们会发现这一代除了多出了一个额外的 Tensor Core 的单元以外，怎么 SM 的体积看起来好像又加回去了，每个 SM 中包含：</p>
<ul>
<li>4 个 Warp Scheduler，4 个 Dispatch Unit（发现不需要配 2 个 Dispatch 给每个 Scheduler 了？白皮书里面倒是没有对这个的解释）</li>
<li>64 个 FP32 Core（4 * 16）</li>
<li>64 个 INT32 Core（4 * 16）</li>
<li>32 个 FP64 Core（4 * 8）</li>
<li>8 个 Tensor Core （4 * 2）</li>
<li>32 个 LD/ST Unit（4 * 8）</li>
<li>4 个 SFU（发现对特殊计算的需求减少了？）</li>
</ul>
<p>事实上相比 Pascal 而言，单个 SM 中的单精运算单元数量是一致的，相当于把 Pascal 中的每个 Process Block 进一步地又拆成了 2 个，每个 Process Block 中包含：</p>
<ul>
<li>1 个 Warp Scheduler，1 个 Dispatch Unit</li>
<li>16 个 FP32 Core</li>
<li>16 个 INT32 Core</li>
<li>8 个 FP64 Core</li>
<li>2 个 Tensor Core</li>
<li>8 个 LD/ST Unit</li>
<li>1 个 SFU</li>
</ul>
<p>这里把原本的 CUDA Core 给拆开了，FP32 和 INT32 的两组运算单元现在是独立出现在流水线 lane 里面了，这一设计的好处是在前几代架构中 CUDA Core 同时只能处理一种类型的运算，而现在每个 cycle 都可以同时有 FP32 和 INT32 的指令在一起跑了。Pascal 中需要 6 个 cycles 来做一组 FMA，现在在 Volta 中只需要 4 个 cycles。</p>
<p>另外每个 Warp Scheduler 还有了自己的 L0 指令 cache。</p>
<p>这一代还改进了一下 MPS，现在从硬件上直接支持对资源的隔离，方便多任务共享 GPU。</p>
<p>其他一些比较重要的改进：</p>
<h3 id="Tensor-Core"><a href="#Tensor-Core" class="headerlink" title="Tensor Core"></a>Tensor Core</h3><p>最重大的改动不用说也知道是 Tensor Core 了。</p>
<p>Tensor Core 的思路从系统设计上还是相当直接的，目前深度学习的 workload 中最主要的计算量都在矩阵的乘加上，因此为了专门去高效地支持这些 workload，就增加一些专用于矩阵运算的专用部件进去。</p>
<p>这个也是常见的 AI ASIC（比如 Google 的 TPU、其他厂商的各种 xPU 等等）通常采用的思路，只不过 ASIC 可以从一开始就是针对特定的 workload 去的，因此设计上可以更直接更激进一些，直接上大量的 MMU（Matrix Multiply Unit），然后采用例如脉冲阵列这种设计去最大化它的 throughput。</p>
<p>而 NV 的 GPU 毕竟还要用作其他一些通用的运算，所以只能往原本的 SM 流水线里面插进去一些额外的专用部件 lane 了。开个脑洞，要是哪一天发现除了 FMA 以外还有其他另外一种形式的运算有大量的需求，未来的 GPU 设计里面说不定也会出现其他 xx Core。好在 FMA 除了深度学习以外在 HPC 的 workload 里面也是挺常见的，这个设计以后还是比较有用的。</p>
<p><img data-src="https://jcf94.com/download/2020-05-24-nvidia-arch-tensorcore1.png" alt="Tensor Core 4x4 Matrix Multiply and Accumulate"></p>
<p><img data-src="https://jcf94.com/download/2020-05-24-nvidia-arch-tensorcore2.png" alt="Mixed Precision Multiply and Accumulate in Tensor Core"></p>
<p>Tensor Core 这个部件直接从 SM 的寄存器里面取两个 FP16 的矩阵作为输入，进行全精度的矩阵乘之后得到的结果可以是 FP16 或者 FP32 的，然后累加到 FP16/FP32 的 accumulator 里面去。数据类型选择 FP16 作为输入然后输出 FP32 猜测可能是为了保证结果不溢出，然后在加速部件设计等等方面做了一些 trade off。</p>
<blockquote>
<p>所以 FP16 in -&gt; FP16 out 和 FP16 in -&gt; FP32 out 哪一个性能更好呢…<br>我没有测过，但是猜测可能默认结果是 FP32 out 更快？反而是输出 FP16 需要从 FP32 再转一次？</p>
</blockquote>
<hr>
<p>接下来道理我们都懂了，那 Tensor Core 要怎么用呢？这个部件的编程模型在一开始接触的时候可能会有一些坑。</p>
<p>我们知道常规的 CUDA 代码需要制定 grid 的结构、block 的结构，然后其实我们写的 kernel 代码都是针对每一个单独的 thread 的，可以认为是 thread level 的编程。对一个子矩阵的 FMA 运算存在比较多的数据重用机会，这时候如果只是一个 thread 算一个矩阵块的 FMA 就比较浪费了，因此 Tensor Core 的设计是用一整个 warp 去共同完成一个 FMA 运算，一个 warp 中的 32 个 thread 可以复用寄存器里面的数据。CUDA 对 Tensor Core 的指南里面把这个叫做 “WMMA warp-wide macro-instructions”。所以 Tensor Core 的编程模型直接就是针对一整个 warp 写的。</p>
<p>事实上，Tensor Core 的代码写起来还是有相当多的限制的，CUDA 给 Tensor Core 提供了以下这些 c 的 API：</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">template</span>&lt;<span class="keyword">typename</span> Use, <span class="keyword">int</span> m, <span class="keyword">int</span> n, <span class="keyword">int</span> k, <span class="keyword">typename</span> T, <span class="keyword">typename</span> Layout=<span class="keyword">void</span>&gt; class fragment;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">load_matrix_sync</span><span class="params">(fragment&lt;...&gt; &amp;a, <span class="keyword">const</span> T* mptr, <span class="keyword">unsigned</span> ldm)</span></span>;</span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">load_matrix_sync</span><span class="params">(fragment&lt;...&gt; &amp;a, <span class="keyword">const</span> T* mptr, <span class="keyword">unsigned</span> ldm, <span class="keyword">layout_t</span> layout)</span></span>;</span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">store_matrix_sync</span><span class="params">(T* mptr, <span class="keyword">const</span> fragment&lt;...&gt; &amp;a, <span class="keyword">unsigned</span> ldm, <span class="keyword">layout_t</span> layout)</span></span>;</span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">fill_fragment</span><span class="params">(fragment&lt;...&gt; &amp;a, <span class="keyword">const</span> T&amp; v)</span></span>;</span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">mma_sync</span><span class="params">(fragment&lt;...&gt; &amp;d, <span class="keyword">const</span> fragment&lt;...&gt; &amp;a, <span class="keyword">const</span> fragment&lt;...&gt; &amp;b, <span class="keyword">const</span> fragment&lt;...&gt; &amp;c, <span class="keyword">bool</span> satf=<span class="literal">false</span>)</span></span>;</span><br></pre></td></tr></table></figure>

<p>PTX 的指令应该更多一些，不过我没有详细看过。</p>
<p>首先用来做乘加的矩阵都需要放在这个叫 <code>wmma::fragment</code> 的变量里面，这个本质上就是定义了一个要放在 SM 寄存器上的存储空间，但是需要提供详细的 FMA 参数：</p>
<ul>
<li>第一个参数 <code>Use</code> 是这个 <code>fragment</code> 在 FMA 运算里面的角色，可选项有：<code>matrix_a</code>、<code>matrix_b</code> 和 <code>accumulator</code>，含义就是字面意思，也没什么需要再解释的了。</li>
<li>m，n，k，T 是这一个 warp 里面要处理的的 FMA 子矩阵的形状以及数据类型，不同的 Capability 能够支持的组合还不太一样，比如最基础的就是 a、b 都是 <code>__half</code>，accumulator 是 <code>float</code>，然后 m、n、k 都是 16。<br>m、n、k 的组合不是任意的，能支持的种类跟 Capability 直接相关，比如 V100 和后来出的 T4 能够支持的就不一样，具体可以在 <a href="https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#wmma-type-sizes" target="_blank" rel="noopener">Programming Guide</a> 里面查。</li>
<li>最后这个 <code>Layout</code> 可选项有两个 <code>row_major</code> 和 <code>col_major</code>，代表这个 <code>fragment</code> 在内存里面实际存储的行列主序情况。</li>
</ul>
<p><code>load_matrix_sync</code> 和 <code>store_matrix_sync</code> 分别是把数据写到 <code>fragment</code> 空间里面和从这里面取出来写到别的地方去。<code>fill_fragment</code> 对 <code>fragment</code> 初始化。<code>mma_sync</code> 就是对整个 warp 调用 Tensor Core 去跑完这一个 FMA 运算了。</p>
<p>常规的写法也是先把矩阵 A、B 都 load 到 shared_memory 上，然后再从 shared_memory 里面取对应 FMA 块大小的数据到 <code>fragment</code> 里面，<code>mma_sync</code> 跑完，最后从 <code>fragment</code> 里面把结果写到外面去。</p>
<p>这里的注意点是上面这些代码（包括 <code>fragment</code> 定义以及下面几个函数的调用）都是<strong>针对 warp</strong> 的，即我们在写代码的一开始就需要考虑到每个 block 里面的 thread 结构，保证一个 warp 的 32 个 thread 执行的代码是完全相同的。相应地，对矩阵的分块也是需要在写代码的时候就考虑清楚，我们要保证每个 warp 处理的 a、b 矩阵的大小刚好是这个地方设定好的 m、n、k。</p>
<blockquote>
<p>看起来确实相当麻烦，不过想想可能好像也还好，本来如果要写出性能很好的 CUDA 代码来，每个 warp 要算多少东西也是需要精细考虑清楚的。</p>
</blockquote>
<h3 id="SIMT-Model-Upgrade-amp-COOPERATIVE-GROUPS"><a href="#SIMT-Model-Upgrade-amp-COOPERATIVE-GROUPS" class="headerlink" title="SIMT Model Upgrade &amp; COOPERATIVE GROUPS"></a>SIMT Model Upgrade &amp; COOPERATIVE GROUPS</h3><p>Volta 这一代对 SIMT 的编程模型也做了改变。</p>
<p>在之前的 SIMT 流水线中，如果一个 warp 的指令里面出现了分支，这些分支块是不能被同时执行的。所以一直以来写 CUDA 代码都会要有一个原则是不要在一个 warp 里面出现不同的分支，要不需要花费两倍的时间去处理。</p>
<p><img data-src="https://jcf94.com/download/2020-05-24-nvidia-arch-simt-old.png" alt="SIMT Warp Execution Model of Pascal and Earlier GPUs"></p>
<p>这一代开始把 PC 和调用栈做成了每个线程独立的：</p>
<p><img data-src="https://jcf94.com/download/2020-05-24-nvidia-arch-simt-design.png" alt="Volta Warp with Per-Thread Program Counter and Call Stack"></p>
<p>现在呢，每个分支里面的指令可以在更细粒度的层面上进行混合调度了，也可以手动插入一些在 warp 层面同步的指令进去：</p>
<p><img data-src="https://jcf94.com/download/2020-05-24-nvidia-arch-simt-new.png" alt="Programs use Explicit Synchronization to Reconverge Threads in a Warp"></p>
<p>白皮书后面给了一个可以从这个改动上得到收益的 Starvation-Free Algorithms 的示例，修改带锁的双向链表的时候，不同 thread 可能会被 block 在锁上，以前的架构应该基本上不太可能能处理得了这种 case，新架构就保证了即使有些 thread 还在等待锁，另外的 thread 也有可能先拉出来跑。</p>
<blockquote>
<p>可能也是因为这样所以 1 个 Dispatch Unit 配 1 个 Warp Scheduler 了？因为线程指令的实现事实上更加复杂了。<br>所以其实最后还是同时只能执行一个分支里面的一部分，这个 upgrade 我暂时还没有想到具体的应用场景会有多常出现（上面这个带锁双向链表我觉得写在 CUDA 里面就很不常见啊…），以及会具体有多少性能收益，说不定还是原本的那种简单的设计更直接更高效一些呢。（期待一下未来的硬件里面会不会把这个恢复回去……）<br>以前 CUDA 编程原则里面不要写分支的那条在新架构下我觉得还是适用的，不写分支就不会有这么多额外的麻烦要考虑了。</p>
</blockquote>
<p>另外有一个 Cooperative Group 的新设计倒是看起来感觉更有用一些。原本的 <code>__syncthreads( )</code> 是针对一个 block 里面的所有 thread 做同步的，现在可以对不同 block 的不同 thread 单独定义同步组了，CUDA launch 的时候会把同一个组的一起 launch 上去，同步可以在一个更加细粒度的层面上完成。</p>
<h2 id="Turing"><a href="#Turing" class="headerlink" title="Turing"></a>Turing</h2><p>Compute Capability: 7.5</p>
<h1 id="Ampere"><a href="#Ampere" class="headerlink" title="Ampere"></a>Ampere</h1><p>Compute Capability: 8.0</p>
<hr>
<p>To be continued.</p>

    </div>

    
    
    
      
  <div class="popular-posts-header">Related Posts</div>
  <ul class="popular-posts">
    <li class="popular-posts-item">
      <div class="popular-posts-title"><a href="/2018/02/13/2018-02-13-intel/" rel="bookmark">Intel 处理器架构演进</a></div>
    </li>
  </ul>


      <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/Microarchitecture/" rel="tag"># Microarchitecture</a>
              <a href="/tags/NVIDIA/" rel="tag"># NVIDIA</a>
          </div>

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2020/03/08/2020-03-08-tvm2/" rel="prev" title="TVM 拆包（二）：IR">
      <i class="fa fa-chevron-left"></i> TVM 拆包（二）：IR
    </a></div>
      <div class="post-nav-item"></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          
    <div class="comments" id="gitalk-container"></div>

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#Tesla"><span class="nav-text">Tesla</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Fermi"><span class="nav-text">Fermi</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Kepler"><span class="nav-text">Kepler</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Maxwell"><span class="nav-text">Maxwell</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Pascal"><span class="nav-text">Pascal</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Volta"><span class="nav-text">Volta</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Tensor-Core"><span class="nav-text">Tensor Core</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#SIMT-Model-Upgrade-amp-COOPERATIVE-GROUPS"><span class="nav-text">SIMT Model Upgrade &amp; COOPERATIVE GROUPS</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Turing"><span class="nav-text">Turing</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Ampere"><span class="nav-text">Ampere</span></a></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="Jcf94"
      src="/photo.jpg">
  <p class="site-author-name" itemprop="name">Jcf94</p>
  <div class="site-description" itemprop="description">To live is to change the world.</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives">
          <span class="site-state-item-count">157</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
        <span class="site-state-item-count">18</span>
        <span class="site-state-item-name">categories</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
        <span class="site-state-item-count">163</span>
        <span class="site-state-item-name">tags</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/jcf94" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;jcf94" rel="noopener" target="_blank"><i class="fa fa-fw fa-github"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="http://weibo.com/jcf94" title="Weibo → http:&#x2F;&#x2F;weibo.com&#x2F;jcf94" rel="noopener" target="_blank"><i class="fa fa-fw fa-weibo"></i>Weibo</a>
      </span>
      <span class="links-of-author-item">
        <a href="http://www.zhihu.com/people/jcf94" title="Zhihu → http:&#x2F;&#x2F;www.zhihu.com&#x2F;people&#x2F;jcf94" rel="noopener" target="_blank"><i class="fa fa-fw fa-book"></i>Zhihu</a>
      </span>
      <span class="links-of-author-item">
        <a href="https://cn.linkedin.com/in/jcf94/en" title="Linked-in → https:&#x2F;&#x2F;cn.linkedin.com&#x2F;in&#x2F;jcf94&#x2F;en" rel="noopener" target="_blank"><i class="fa fa-fw fa-linkedin"></i>Linked-in</a>
      </span>
  </div>
  <div class="cc-license motion-element" itemprop="license">
    <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" class="cc-opacity" rel="noopener" target="_blank"><img src="/images/cc-by-nc-sa.svg" alt="Creative Commons"></a>
  </div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 2014 – 
  <span itemprop="copyrightYear">2020</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Jcf94</span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Gemini</a>
  </div>

        
<div class="busuanzi-count">
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
    <span class="post-meta-item" id="busuanzi_container_site_uv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="Total Visitors">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item" id="busuanzi_container_site_pv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="Total Views">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="//cdn.jsdelivr.net/npm/jquery@3/dist/jquery.min.js"></script>
  <script src="//cdn.jsdelivr.net/gh/fancyapps/fancybox@3/dist/jquery.fancybox.min.js"></script>
  <script src="//cdn.jsdelivr.net/npm/lozad@1/dist/lozad.min.js"></script>
  <script src="//cdn.jsdelivr.net/npm/pangu@4/dist/browser/pangu.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>




  
  <script>
    (function(){
      var bp = document.createElement('script');
      var curProtocol = window.location.protocol.split(':')[0];
      bp.src = (curProtocol === 'https') ? 'https://zz.bdstatic.com/linksubmit/push.js' : 'http://push.zhanzhang.baidu.com/push.js';
      var s = document.getElementsByTagName("script")[0];
      s.parentNode.insertBefore(bp, s);
    })();
  </script>




  
<script src="/js/local-search.js"></script>













  

  

  

<link rel="stylesheet" href="//cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.min.css">

<script>
NexT.utils.loadComments(document.querySelector('#gitalk-container'), () => {
  NexT.utils.getScript('//cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.min.js', () => {
    var gitalk = new Gitalk({
      clientID    : '53c17a207b0eb9315f41',
      clientSecret: 'e697661132cf0936345a27b937f76074f55002be',
      repo        : 'blog-comments',
      owner       : 'jcf94',
      admin       : ['jcf94'],
      // id          : '448756a9bd5946ba38ad05cacd70b23c',
      id          : location.pathname,
        language: 'en',
      distractionFreeMode: true
    });
    gitalk.render('gitalk-container');
  }, window.Gitalk);
});
</script>

</body>
</html>
